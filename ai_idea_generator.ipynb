# ===========================================================
# üí° AI Idea Generator ‚Äî TinyLlama Edition (Google Colab Free)
# ===========================================================

!pip install -q transformers huggingface_hub accelerate

import os
from transformers import pipeline

# üîë –í—Å—Ç–∞–≤—å —Å–≤–æ–π Hugging Face —Ç–æ–∫–µ–Ω
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hf_–¢–í–û–ô_–¢–û–ö–ï–ù_–°–Æ–î–ê"

# üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—ë–≥–∫—É—é open-source –º–æ–¥–µ–ª—å
generator = pipeline(
    "text-generation",
    model="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    torch_dtype="auto",
    device_map="auto"
)

# --- –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–¥–µ–π ---
def generate_idea(topic, style="–∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É"):
    prompt = f"–¢—ã ‚Äî –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –ü—Ä–∏–¥—É–º–∞–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –∏–¥–µ—é –ø–æ —Ç–µ–º–µ: {topic}. –û–ø–∏—à–∏ {style}."
    response = generator(prompt, max_new_tokens=80, temperature=0.8)[0]["generated_text"]
    return response

# --- –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
print("üí° AI Idea Generator (TinyLlama)")
topic = input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–¥–µ–π: ")

# --- –†–µ–∑—É–ª—å—Ç–∞—Ç ---
idea = generate_idea(topic)
print("\n‚ú® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–¥–µ—è:\n")
print(idea)
